# Kaggle-Natural-Language-Processing
Kaggle-Natural-Language-Processing



-------
-------

# Natural Language Processing
https://www.youtube.com/playlist?list=PL1v8zpldgH3pQwRz1FORZdChMaNZaR3pu


1

27:33
NOW PLAYING
GPT-2: Language Models are Unsupervised Multitask Learners
Yannic Kilcher

2

40:13
NOW PLAYING
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
Yannic Kilcher

3

18:19
NOW PLAYING
Stochastic RNNs without Teacher-Forcing
Yannic Kilcher

4

27:07
NOW PLAYING
Attention Is All You Need
Yannic Kilcher

5

30:06
NOW PLAYING
XLNet: Generalized Autoregressive Pretraining for Language Understanding
Yannic Kilcher

6

19:15
NOW PLAYING
RoBERTa: A Robustly Optimized BERT Pretraining Approach
Yannic Kilcher

7

30:22
NOW PLAYING
LeDeepChef üë®‚Äçüç≥ Deep Reinforcement Learning Agent for Families of Text-Based Games
Yannic Kilcher

8

29:12
NOW PLAYING
Reformer: The Efficient Transformer
Yannic Kilcher

9

21:18
NOW PLAYING
Turing-NLG, DeepSpeed and the ZeRO optimizer
Yannic Kilcher

10

24:16
NOW PLAYING
Deep Learning for Symbolic Mathematics
Yannic Kilcher

11

18:59
NOW PLAYING
Evaluating NLP Models via Contrast Sets
Yannic Kilcher

12

18:15
NOW PLAYING
Imputer: Sequence Modelling via Imputation and Dynamic Programming
Yannic Kilcher

13

26:36
NOW PLAYING
Longformer: The Long-Document Transformer
Yannic Kilcher

14

11:21
NOW PLAYING
I talk to the new Facebook Blender Chatbot
Yannic Kilcher

15

31:48
NOW PLAYING
TAPAS: Weakly Supervised Table Parsing via Pre-training (Paper Explained)
Yannic Kilcher

16

1:02:41
NOW PLAYING
[Code] PyTorch sentiment classifier from scratch with Huggingface NLP Library (Full Tutorial)
Yannic Kilcher

17

11:11
NOW PLAYING
[News] OpenAI Model Generates Python Code
Yannic Kilcher

18

53:35
NOW PLAYING
When BERT Plays the Lottery, All Tickets Are Winning (Paper Explained)
Yannic Kilcher

19

53:35
NOW PLAYING
When BERT Plays the Lottery, All Tickets Are Winning (Paper Explained)
Yannic Kilcher

20

1:04:30
NOW PLAYING
GPT-3: Language Models are Few-Shot Learners (Paper Explained)
Yannic Kilcher

21

48:21
NOW PLAYING
Synthesizer: Rethinking Self-Attention in Transformer Models (Paper Explained)
Yannic Kilcher

22

30:11
NOW PLAYING
Movement Pruning: Adaptive Sparsity by Fine-Tuning (Paper Explained)
Yannic Kilcher

23

31:35
NOW PLAYING
BLEURT: Learning Robust Metrics for Text Generation (Paper Explained)
Yannic Kilcher

24

31:35
NOW PLAYING
BLEURT: Learning Robust Metrics for Text Generation (Paper Explained)
Yannic Kilcher

25

48:38
NOW PLAYING
TransCoder: Unsupervised Translation of Programming Languages (Paper Explained)
Yannic Kilcher

26

48:38
NOW PLAYING
TransCoder: Unsupervised Translation of Programming Languages (Paper Explained)
Yannic Kilcher

27

50:24
NOW PLAYING
Linformer: Self-Attention with Linear Complexity (Paper Explained)
Yannic Kilcher

28

50:24
NOW PLAYING
Linformer: Self-Attention with Linear Complexity (Paper Explained)
Yannic Kilcher

29

50:24
NOW PLAYING
Linformer: Self-Attention with Linear Complexity (Paper Explained)
Yannic Kilcher

30

50:24
NOW PLAYING
Linformer: Self-Attention with Linear Complexity (Paper Explained)
Yannic Kilcher

31

50:24
NOW PLAYING
Linformer: Self-Attention with Linear Complexity (Paper Explained)
Yannic Kilcher

32

50:24
NOW PLAYING
Linformer: Self-Attention with Linear Complexity (Paper Explained)
Yannic Kilcher

33

50:24
NOW PLAYING
Linformer: Self-Attention with Linear Complexity (Paper Explained)
Yannic Kilcher

34

29:42
NOW PLAYING
VirTex: Learning Visual Representations from Textual Annotations (Paper Explained)
Yannic Kilcher

35

29:42
NOW PLAYING
VirTex: Learning Visual Representations from Textual Annotations (Paper Explained)
Yannic Kilcher

36

36:49
NOW PLAYING
Deep Differential System Stability - Learning advanced computations from examples (Paper Explained)
Yannic Kilcher

37

36:49
NOW PLAYING
Deep Differential System Stability - Learning advanced computations from examples (Paper Explained)
Yannic Kilcher

38

1:13:04
NOW PLAYING
GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding (Paper Explained)
Yannic Kilcher

39

1:13:04
NOW PLAYING
GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding (Paper Explained)
Yannic Kilcher

40

36:50
NOW PLAYING
BERTology Meets Biology: Interpreting Attention in Protein Language Models (Paper Explained)
Yannic Kilcher

41

36:50
NOW PLAYING
BERTology Meets Biology: Interpreting Attention in Protein Language Models (Paper Explained)
Yannic Kilcher

42

48:06
NOW PLAYING
Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention (Paper Explained)
Yannic Kilcher

43

31:22
NOW PLAYING
[Classic] Word2Vec: Distributed Representations of Words and Phrases and their Compositionality
Yannic Kilcher

44

31:22
NOW PLAYING
[Classic] Word2Vec: Distributed Representations of Words and Phrases and their Compositionality
Yannic Kilcher

45

34:30
NOW PLAYING
Big Bird: Transformers for Longer Sequences (Paper Explained)
Yannic Kilcher

46

1:05:16
NOW PLAYING
Hopfield Networks is All You Need (Paper Explained)
Yannic Kilcher

47

1:00:41
NOW PLAYING
REALM: Retrieval-Augmented Language Model Pre-Training (Paper Explained)
Yannic Kilcher

48

45:30
NOW PLAYING
Learning to summarize from human feedback (Paper Explained)
Yannic Kilcher

49

54:39
NOW PLAYING
Rethinking Attention with Performers (Paper Explained)
Yannic Kilcher

50

52:16
NOW PLAYING
Language Models are Open Knowledge Graphs (Paper Explained)
Yannic Kilcher

51

1:03:18
NOW PLAYING
Extracting Training Data from Large Language Models (Paper Explained)
Yannic Kilcher

52

55:46
NOW PLAYING
OpenAI DALL¬∑E: Creating Images from Text (Blog Post Explained)
Yannic Kilcher

53

48:07
NOW PLAYING
OpenAI CLIP: ConnectingText and Images (Paper Explained)
Yannic Kilcher

54

33:47
NOW PLAYING
Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity
Yannic Kilcher

55

43:51
NOW PLAYING
Feedback Transformers: Addressing Some Limitations of Transformers with Feedback Memory (Explained)
Yannic Kilcher

56

48:12
NOW PLAYING
Nystr√∂mformer: A Nystr√∂m-Based Algorithm for Approximating Self-Attention (AI Paper Explained)
Yannic Kilcher

57

45:14
NOW PLAYING
DeBERTa: Decoding-enhanced BERT with Disentangled Attention (Machine Learning Paper Explained)
Yannic Kilcher

58

31:22
NOW PLAYING
ALiBi - Train Short, Test Long: Attention with linear biases enables input length extrapolation
Yannic Kilcher

59

36:37
NOW PLAYING
‚àû-former: Infinite Memory Transformer (aka Infty-Former / Infinity-Former, Research Paper Explained)
Yannic Kilcher

60

13:19
NOW PLAYING
Does GPT-3 lie? - Misinformation and fear-mongering around the TruthfulQA dataset
Yannic Kilcher

61

45:22
NOW PLAYING
Symbolic Knowledge Distillation: from General Language Models to Commonsense Models (Explained)
Yannic Kilcher

62

57:07
NOW PLAYING
Sparse is Enough in Scaling Transformers (aka Terraformer) | ML Research Paper Explained
Yannic Kilcher

-------
-------

